# Child-of-Now (Team 20)

Created Date: 26/08/2020\
Last Updated Date: 26/08/2020

> Created by team-20 in COMP90082 from UniMelb\
> Contributors: [Lingxuan](https://github.com/kongpeter), 



# Introduction

## Background (Ziyue)

Focusing on the question "What will the life of a child born now look like?", the "Children Now" project will collectively imagine the 100-year lifetime of a child born in 2020, creating a rare and extraordinary moment in the life of the Victorian era. Participants and visitors will have the opportunity to consciously sympathize with the next generation, who will inherit our culture, customs, and impact on the environment.

The project is expected to take ten days in 2021 to show people the 100 years of a "person" in the form of a 144-meter tall augmented reality (AR) sculpture. In the project, we collected the personal portraits and voices of 14,400 participants from all walks of life.  fully represent the diversity of life in Victoria with different cultures, ages, languages, bodies, genders and voices. After sorting these portraits by the age of the participants, the giant will grow every minute for 10 days. When it grows from 1 to 100, the statue will continue to age by switching the face, body and voice of the contributor. People can see every moment of the life of the statue above Hammer Concert Hall through large screens and mobile phones, and can also watch screens throughout the city and around the world through real-time streaming.

For our team 20, our main task is divided into two parts: creating a mesh from Point cloud data captured from Azure for Kinect arrays and making an interactive interface suitable for people to enjoy our project.



## Scope (Ziyue)
### In scope
#### Target
In this project, the target of team 20 is to convert the collected data into images and capture and output the portraits, and then design an interactive interface as much as possible to allow users to better enjoy the results of our project. 

#### Features
1. Portraits should be capture from the central area without background.
2. Three camera should be implemented with individual output in the same fashion as above.
3. Recording can be started and stopped by technician on tablet or workstation
4. Recording can be started and stopped by user pressing button
5. Recording can run for a set time.
6. A ‘3, 2, 1’ countdown sound plays once button pressed.
7. A sound indicates when recording begins and end.
8. Sounds can play during the recording that contain instructions for the user or music.
9. Video or image can be displayed on the user screen while the recording plays.
10. quickly see if every prompt or instruction in a session has a take [are there any gaps]
11. quickly see if any prompt or instruction has more than one take [so they know they have to select the best one]
12. select the best take for an individual instruction or prompt
13. delete or move takes from a recording session
14. add a take from another recording session
15. save the recording session in the library

### Out of scope
1. Collect data of participants.
2. Process audio files of participants.

## Use Cases (Lingxuan)

* **SuD**: The mesh cloud to point system. 
* **Actor**: 14,400 Victorians, Cameras.

> Scenario 1: The cameras scan user's movement and successfully generate a 3D, high-resolution, moving holograms of the user body.

> Scenario 2: The cameras scan user's movement, but fail to generate the moving holograms. Then the system will scan user again to analysis and generate moving holograms.

> Scenario 3: The user is not satisfied with the exciting moving holograms, he can require the system to scan and generate a new one. 





# Requirements (Zheng Tang)



# Project Prototypes (Zheng Tang)





# Project Plan (Wenkang)





# Goal Models (Wenkang)





# Development Environment (Martin)
